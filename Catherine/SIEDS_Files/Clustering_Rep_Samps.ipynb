{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering the Representative Samples for Day 3\n",
    "# Catherine Beazley"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.301319360733032\n"
     ]
    }
   ],
   "source": [
    "# Reading 10 million row representative sample of the data \n",
    "start = time.time()\n",
    "df1 = pd.read_csv('RepresentativeSample_10million.csv')\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32.27336120605469\n"
     ]
    }
   ],
   "source": [
    "# Reading 20 million row representative sample of the data \n",
    "start = time.time()\n",
    "df2 = pd.read_csv('RepresentativeSample_20million.csv')\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cosine Similarity (used in clustering algorithm)\n",
    "def cosine_similarity(slope1, slope2):\n",
    "    a = np.array([1,slope1])\n",
    "    b = np.array([1,slope2])\n",
    "    return np.dot(a, b)/(np.linalg.norm(a)*np.linalg.norm(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster Packet Scatterplot\n",
    "def slope_classifier(k, x_coords, y_coords):    \n",
    "    # Randomly assigning initial clusters\n",
    "    slopeClusters = []\n",
    "    for i in range(k):\n",
    "        slopeClusters.append((random.uniform(0,math.pi/2)))\n",
    "    \n",
    "    # Finding the ratio of y to x (slope for each (x,y) coordinate)\n",
    "    # Making x values of 0 very small to avoid divide by zero error\n",
    "    xCopy = x_coords\n",
    "    xCopy[xCopy==0] = 0.0000000000000000000001\n",
    "    y = np.array(y_coords, dtype = 'float')\n",
    "    x = np.array(xCopy, dtype = 'float')\n",
    "    slopes = np.divide(y,x)\n",
    "    \n",
    "    \n",
    "    # Instantiating and empty array of 0 as a place holder for the old slope clusters\n",
    "    # will use this to calculate error as slope clusters change each iteration. Once the error\n",
    "    # is 0, the clusters have stabilized\n",
    "    old_slopeClusters = np.zeros(len(slopeClusters))\n",
    "    error = np.divide(np.subtract(slopeClusters, old_slopeClusters), old_slopeClusters)\n",
    "  \n",
    "    # Running a loop until centroids stabilize (percent change from old cluster values to new is 0)\n",
    "    while error.any() != 0:\n",
    "        \n",
    "        # Instantiating an empty array of 0s that will be populated with cluster assignments for each slope  \n",
    "        clusters = np.zeros(len(slopes))\n",
    "        \n",
    "        # For each slope, find the cosine distance to each cluster. Cosine always return [0,1], with values\n",
    "        # closer to 1 signifying that the two vectors are close; 0 that they are far apart. Finding the max\n",
    "        # cosine value and the corresponding cluster will be assigned to that slope. \n",
    "        for i in range(len(slopes)):               \n",
    "            distances = []\n",
    "            for j in range(len(slopeClusters)):\n",
    "                distances.append(cosine_similarity(slopes[i],slopeClusters[j]))\n",
    "            cluster = np.argmax(distances)\n",
    "            clusters[i] = cluster\n",
    "        \n",
    "               \n",
    "        # Making a deep copy of the old centroids to use later for clacluating error\n",
    "        old_slopeClusters = deepcopy(slopeClusters)\n",
    "        \n",
    "        \n",
    "        # Finding new centroids by taking average of the values assigned to each cluster and\n",
    "        # replacing the old cluster values with the new averages\n",
    "        for m in range(k):\n",
    "            points = [slopes[j] for j in range(len(slopes)) if clusters[j] == m]              \n",
    "            slopeClusters[m] = sum(points)/len(points)\n",
    "        \n",
    "        # Finding the percent change from the old cluster assignments to the new cluster assignments\n",
    "        error = np.divide(np.subtract(slopeClusters, old_slopeClusters), old_slopeClusters)\n",
    "        \n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/apps/software/standard/core/anaconda/5.2.0-py3.6/lib/python3.6/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/apps/software/standard/core/anaconda/5.2.0-py3.6/lib/python3.6/site-packages/ipykernel_launcher.py:21: RuntimeWarning: divide by zero encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2595.0166223049164\n"
     ]
    }
   ],
   "source": [
    "# Clustering the 10 million Random Sample\n",
    "start = time.time()\n",
    "clusters10 = slope_classifier(3,df1[\"SrcPackets\"], df1[\"DstPackets\"])\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96.65129280090332\n"
     ]
    }
   ],
   "source": [
    "# Appending the clusters as a column and writing the dataframe to a csv\n",
    "start = time.time()\n",
    "df1[\"PacketClusterAssignment\"] = clusters10\n",
    "df1.to_csv('RepSamp_10million_with_packet_clusters.csv')\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/apps/software/standard/core/anaconda/5.2.0-py3.6/lib/python3.6/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/apps/software/standard/core/anaconda/5.2.0-py3.6/lib/python3.6/site-packages/ipykernel_launcher.py:21: RuntimeWarning: divide by zero encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3746.552615404129\n"
     ]
    }
   ],
   "source": [
    "# Clustering the 20 million Random Sample\n",
    "start = time.time()\n",
    "clusters20 = slope_classifier(3,df2[\"SrcPackets\"], df2[\"DstPackets\"])\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "279.57945561408997\n"
     ]
    }
   ],
   "source": [
    "# Appending the clusters as a column and writing the dataframe to a csv\n",
    "start = time.time()\n",
    "df2[\"PacketClusterAssignment\"] = clusters20\n",
    "df2.to_csv('RepSamp_20million_with_packet_clusters.csv')\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
